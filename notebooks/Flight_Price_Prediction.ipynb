{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flight Price Prediction - End-to-End Machine Learning Project\n",
        "\n",
        "## Project Overview\n",
        "This notebook presents a complete machine learning solution for predicting flight ticket prices. Flight prices are highly dynamic and influenced by multiple factors including departure time, airline, route, number of stops, and booking date.\n",
        "\n",
        "## Business Problem\n",
        "Airlines and travelers need accurate price predictions to:\n",
        "- **Airlines**: Optimize pricing strategies and revenue management\n",
        "- **Travelers**: Make informed booking decisions and find the best deals\n",
        "- **Travel Agencies**: Provide price recommendations to customers\n",
        "\n",
        "## Dataset\n",
        "The dataset contains historical flight booking data with features such as airline, journey date, source, destination, route, departure/arrival times, duration, stops, and price.\n",
        "\n",
        "## Approach\n",
        "We will follow a systematic data science workflow:\n",
        "1. Data Loading & Understanding\n",
        "2. Data Cleaning & Preprocessing\n",
        "3. Feature Engineering\n",
        "4. Exploratory Data Analysis\n",
        "5. Model Training & Comparison\n",
        "6. Hyperparameter Tuning\n",
        "7. Model Selection & Deployment\n",
        "\n",
        "## Success Metrics\n",
        "- **R² Score**: Measures the proportion of variance explained by the model\n",
        "- **RMSE**: Root Mean Squared Error - measures average prediction error\n",
        "- **Cross-validation**: Ensures model generalizes well to unseen data\n",
        "\n",
        "---\n",
        "**Author**: Data Science Team  \n",
        "**Date**: November 2025  \n",
        "**Python Version**: 3.8+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 01 - Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "# Date and time operations\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning - Preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Machine Learning - Models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Machine Learning - Metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Model persistence\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# System operations\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"XGBoost version: {xgb.__version__}\")\n",
        "print(f\"LightGBM version: {lgb.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Imports all necessary libraries for data manipulation, visualization, machine learning, and model persistence.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **pandas/numpy**: Data manipulation and numerical operations\n",
        "- **matplotlib/seaborn**: Professional visualizations\n",
        "- **scikit-learn**: ML preprocessing and evaluation\n",
        "- **XGBoost/LightGBM**: State-of-the-art gradient boosting algorithms\n",
        "- **joblib**: Model serialization for deployment\n",
        "\n",
        "**Best Practice:**  \n",
        "Organizing imports by category improves readability and maintainability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 02 - Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract dataset from zip file\n",
        "zip_file_path = 'flight-fare.zip'\n",
        "\n",
        "# Check if zip file exists\n",
        "if os.path.exists(zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('data/')\n",
        "    print(\"✓ Dataset extracted successfully!\")\n",
        "    print(\"\\nExtracted files:\")\n",
        "    for file in os.listdir('data/'):\n",
        "        print(f\"  - {file}\")\n",
        "else:\n",
        "    if not os.path.exists('data/'):\n",
        "        os.makedirs('data/')\n",
        "    print(f\"⚠ {zip_file_path} not found, will create sample data\")\n",
        "\n",
        "# Load dataset\n",
        "data_files = [f for f in os.listdir('data/') if f.endswith(('.csv', '.xlsx', '.xls'))] if os.path.exists('data/') else []\n",
        "\n",
        "if data_files:\n",
        "    data_file = f\"data/{data_files[0]}\"\n",
        "    print(f\"\\nLoading: {data_file}\")\n",
        "    if data_file.endswith('.csv'):\n",
        "        df = pd.read_csv(data_file)\n",
        "    else:\n",
        "        df = pd.read_excel(data_file)\n",
        "    print(f\"✓ Dataset loaded! Shape: {df.shape}\")\n",
        "else:\n",
        "    # Create realistic sample data\n",
        "    print(\"\\nCreating sample dataset for demonstration...\")\n",
        "    np.random.seed(42)\n",
        "    n = 10819\n",
        "    df = pd.DataFrame({\n",
        "        'Airline': np.random.choice(['IndiGo', 'Air India', 'Jet Airways', 'SpiceJet', \n",
        "                                     'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia'], n),\n",
        "        'Date_of_Journey': pd.date_range('2019-03-01', periods=n, freq='3H').strftime('%d/%m/%Y'),\n",
        "        'Source': np.random.choice(['Delhi', 'Kolkata', 'Mumbai', 'Chennai', 'Bangalore'], n),\n",
        "        'Destination': np.random.choice(['Cochin', 'Bangalore', 'Delhi', 'Hyderabad', 'Mumbai'], n),\n",
        "        'Route': np.random.choice(['DEL-BOM', 'BOM-DEL', 'DEL-BLR', 'BLR-DEL', 'MAA-BOM'], n),\n",
        "        'Dep_Time': [f\"{np.random.randint(0,24):02d}:{np.random.randint(0,60):02d}\" for _ in range(n)],\n",
        "        'Arrival_Time': [f\"{np.random.randint(0,24):02d}:{np.random.randint(0,60):02d}\" for _ in range(n)],\n",
        "        'Duration': [f\"{np.random.randint(1,25)}h {np.random.randint(0,60):02d}m\" for _ in range(n)],\n",
        "        'Total_Stops': np.random.choice(['non-stop', '1 stop', '2 stops', '3 stops', '4 stops'], \n",
        "                                        n, p=[0.25, 0.35, 0.25, 0.10, 0.05]),\n",
        "        'Additional_Info': np.random.choice(['No info', 'In-flight meal not included', \n",
        "                                             'No check-in baggage included', '1 Short layover'], n),\n",
        "        'Price': (np.random.gamma(2.5, 2500, n) + np.random.normal(3000, 1000, n)).astype(int)\n",
        "    })\n",
        "    df['Price'] = df['Price'].clip(lower=1500, upper=80000)\n",
        "    print(f\"✓ Sample dataset created! Shape: {df.shape}\")\n",
        "\n",
        "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Extracts and loads the flight fare dataset, with automatic fallback to sample data creation.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Automatic extraction**: Handles zipped datasets seamlessly\n",
        "- **Format flexibility**: Supports CSV and Excel files\n",
        "- **Fallback mechanism**: Creates realistic sample data if file unavailable\n",
        "- **Initial inspection**: Shows dataset shape and preview\n",
        "\n",
        "**Insights:**  \n",
        "The dataset typically contains 10,000+ flight records with ~11 features. Early shape validation ensures data loaded correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 03 - Understanding Data\n",
        "\n",
        "Deep dive into dataset structure, data types, and distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset dimensions\n",
        "print(\"=\"*70)\n",
        "print(\"DATASET DIMENSIONS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total Rows: {df.shape[0]:,}\")\n",
        "print(f\"Total Columns: {df.shape[1]}\")\n",
        "print(f\"Total Data Points: {df.shape[0] * df.shape[1]:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Displays dataset dimensions (rows and columns).\n",
        "\n",
        "**Why it's needed:**  \n",
        "Understanding scale helps determine computational requirements and whether sampling is needed.\n",
        "\n",
        "**Insight:**  \n",
        "~10,000 rows with 11 columns provides sufficient data for robust model training without computational constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column information\n",
        "print(\"=\"*70)\n",
        "print(\"COLUMN INFORMATION\")\n",
        "print(\"=\"*70)\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET INFO\")\n",
        "print(\"=\"*70)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Shows column names, data types, and non-null counts.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Identifies categorical vs numerical features\n",
        "- Reveals missing values\n",
        "- Guides encoding strategies\n",
        "\n",
        "**Expected findings:**  \n",
        "Object types need encoding; numeric types ready for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"=\"*70)\n",
        "print(\"STATISTICAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "display(df.describe())\n",
        "\n",
        "# Target variable analysis\n",
        "price_col = [col for col in df.columns if 'price' in col.lower()][0]\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"TARGET VARIABLE: {price_col}\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Minimum: ₹{df[price_col].min():,.2f}\")\n",
        "print(f\"Maximum: ₹{df[price_col].max():,.2f}\")\n",
        "print(f\"Mean: ₹{df[price_col].mean():,.2f}\")\n",
        "print(f\"Median: ₹{df[price_col].median():,.2f}\")\n",
        "print(f\"Std Dev: ₹{df[price_col].std():,.2f}\")\n",
        "print(f\"\\nPrice Range: ₹{df[price_col].max() - df[price_col].min():,.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Provides statistical summary of numerical features including central tendency and spread.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Identifies outliers and distribution shape\n",
        "- Shows price range (critical for business context)\n",
        "- Reveals skewness through mean vs median\n",
        "\n",
        "**Key Insights:**  \n",
        "Wide price ranges indicate diverse flight types. High std dev shows significant pricing variability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unique values for categorical columns\n",
        "print(\"=\"*70)\n",
        "print(\"UNIQUE VALUE COUNTS - CATEGORICAL FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Unique values: {unique_count}\")\n",
        "    if unique_count <= 15:\n",
        "        print(f\"  Values: {sorted(df[col].unique()[:15].tolist())}\")\n",
        "    else:\n",
        "        print(f\"  Top 10: {df[col].value_counts().head(10).index.tolist()}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
        "print(f\"Numerical columns: {len(df.select_dtypes(include=[np.number]).columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Counts unique values in each categorical column.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Cardinality assessment**: Determines encoding strategy\n",
        "- **Data validation**: Identifies unexpected values\n",
        "- **Feature planning**: Low cardinality → OneHot, High cardinality → Label/Target encoding\n",
        "\n",
        "**Decision criteria:**\n",
        "- <10 unique: OneHot encoding\n",
        "- 10-50 unique: Label encoding\n",
        "- >50 unique: Target encoding or feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 04 - Data Cleaning\n",
        "\n",
        "Handle missing values, duplicates, and data quality issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing value analysis\n",
        "print(\"=\"*70)\n",
        "print(\"MISSING VALUE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing.index,\n",
        "    'Missing_Count': missing.values,\n",
        "    'Percentage': missing_pct.values\n",
        "}).sort_values('Missing_Count', ascending=False)\n",
        "\n",
        "missing_df = missing_df[missing_df['Missing_Count'] > 0]\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    display(missing_df)\n",
        "    print(f\"\\nTotal columns with missing values: {len(missing_df)}\")\n",
        "else:\n",
        "    print(\"✓ No missing values found!\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Identifies and quantifies missing values across all columns.\n",
        "\n",
        "**Why it's needed:**\n",
        "- ML algorithms can't handle missing data\n",
        "- Determines imputation vs deletion strategy\n",
        "- Assesses data quality\n",
        "\n",
        "**Strategy:**\n",
        "- <5% missing: Drop rows\n",
        "- 5-30%: Impute (mean/median/mode)\n",
        "- >30%: Consider dropping feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "rows_before = len(df)\n",
        "df = df.dropna()\n",
        "rows_after = len(df)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MISSING VALUE TREATMENT\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Rows before: {rows_before:,}\")\n",
        "print(f\"Rows after: {rows_after:,}\")\n",
        "print(f\"Rows dropped: {rows_before - rows_after:,}\")\n",
        "print(f\"Data retained: {(rows_after/rows_before*100):.2f}%\")\n",
        "print(\"\\n✓ Missing values handled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Removes rows with missing values.\n",
        "\n",
        "**Why it's needed:**  \n",
        "Ensures complete data for all features, preventing errors during model training.\n",
        "\n",
        "**Alternative:**  \n",
        "For production with missing data, consider mean/median imputation for numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplicate analysis\n",
        "print(\"=\"*70)\n",
        "print(\"DUPLICATE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Duplicate rows: {duplicates:,}\")\n",
        "\n",
        "if duplicates > 0:\n",
        "    print(f\"Percentage: {(duplicates/len(df)*100):.2f}%\")\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"✓ Duplicates removed! New shape: {df.shape}\")\n",
        "else:\n",
        "    print(\"✓ No duplicates found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Identifies and removes duplicate rows.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Prevents bias toward repeated patterns\n",
        "- Avoids data leakage in train/test split\n",
        "- Ensures unique information per record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outlier detection\n",
        "print(\"=\"*70)\n",
        "print(\"OUTLIER DETECTION - PRICE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "Q1 = df[price_col].quantile(0.25)\n",
        "Q3 = df[price_col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df[price_col] < lower) | (df[price_col] > upper)]\n",
        "\n",
        "print(f\"Q1: ₹{Q1:,.2f}\")\n",
        "print(f\"Q3: ₹{Q3:,.2f}\")\n",
        "print(f\"IQR: ₹{IQR:,.2f}\")\n",
        "print(f\"\\nBounds: ₹{lower:,.2f} to ₹{upper:,.2f}\")\n",
        "print(f\"Outliers: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")\n",
        "print(\"\\n✓ Retaining outliers (legitimate premium/budget flights)\")\n",
        "print(f\"Final shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Uses IQR method to detect price outliers.\n",
        "\n",
        "**Why it's needed:**  \n",
        "Identifies potentially erroneous data points.\n",
        "\n",
        "**Decision:**  \n",
        "We retain outliers because:\n",
        "- High prices = business/first class\n",
        "- Low prices = promotions/budget airlines\n",
        "- Tree models handle outliers well\n",
        "- Removing would lose valuable patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 05 - Feature Engineering\n",
        "\n",
        "Transform raw features into meaningful ML inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Date and Time Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract date features\n",
        "print(\"=\"*70)\n",
        "print(\"DATE FEATURE ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "date_cols = [col for col in df.columns if 'date' in col.lower() or 'journey' in col.lower()]\n",
        "if date_cols:\n",
        "    date_col = date_cols[0]\n",
        "    print(f\"Date column: {date_col}\")\n",
        "    print(f\"Sample: {df[date_col].head(3).tolist()}\")\n",
        "\n",
        "    df[date_col] = pd.to_datetime(df[date_col], dayfirst=True, errors='coerce')\n",
        "\n",
        "    df['Journey_Day'] = df[date_col].dt.day\n",
        "    df['Journey_Month'] = df[date_col].dt.month\n",
        "    df['Journey_Year'] = df[date_col].dt.year\n",
        "    df['Journey_Weekday'] = df[date_col].dt.dayofweek\n",
        "    df['Journey_Weekend'] = (df['Journey_Weekday'] >= 5).astype(int)\n",
        "\n",
        "    print(f\"\\n✓ Created: Journey_Day, Journey_Month, Journey_Year, Journey_Weekday, Journey_Weekend\")\n",
        "    df = df.drop(columns=[date_col])\n",
        "    print(f\"✓ Dropped original: {date_col}\")\n",
        "\n",
        "print(f\"\\nShape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Extracts temporal features from journey date.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Seasonality**: Prices vary by month (holidays, vacations)\n",
        "- **Day patterns**: Weekday vs weekend pricing\n",
        "- **Model compatibility**: ML needs numeric inputs\n",
        "\n",
        "**Feature importance:**\n",
        "- Month captures seasonal demand\n",
        "- Weekday shows business vs leisure patterns\n",
        "- Weekend indicates premium pricing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time feature extraction\n",
        "print(\"=\"*70)\n",
        "print(\"TIME FEATURE ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def extract_hour_minute(time_str):\n",
        "    try:\n",
        "        if pd.isna(time_str):\n",
        "            return None, None\n",
        "        time_str = str(time_str).strip()\n",
        "        if ':' in time_str:\n",
        "            parts = time_str.split(':')\n",
        "            hour = int(parts[0])\n",
        "            minute = int(parts[1][:2])\n",
        "            return hour, minute\n",
        "        return None, None\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "def time_to_minutes(hour, minute):\n",
        "    if hour is not None and minute is not None:\n",
        "        return hour * 60 + minute\n",
        "    return None\n",
        "\n",
        "def categorize_time(hour):\n",
        "    if hour is None:\n",
        "        return 'Unknown'\n",
        "    if 6 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 18:\n",
        "        return 'Afternoon'\n",
        "    elif 18 <= hour < 24:\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Night'\n",
        "\n",
        "# Departure time\n",
        "dep_cols = [col for col in df.columns if 'dep' in col.lower() and 'time' in col.lower()]\n",
        "if dep_cols:\n",
        "    dep_col = dep_cols[0]\n",
        "    print(f\"Processing: {dep_col}\")\n",
        "    df[['Dep_Hour', 'Dep_Minute']] = df[dep_col].apply(lambda x: pd.Series(extract_hour_minute(x)))\n",
        "    df['Dep_Time_Minutes'] = df.apply(lambda x: time_to_minutes(x['Dep_Hour'], x['Dep_Minute']), axis=1)\n",
        "    df['Dep_Time_Period'] = df['Dep_Hour'].apply(categorize_time)\n",
        "    df = df.drop(columns=[dep_col])\n",
        "    print(f\"✓ Created: Dep_Hour, Dep_Minute, Dep_Time_Minutes, Dep_Time_Period\")\n",
        "\n",
        "# Arrival time\n",
        "arr_cols = [col for col in df.columns if 'arr' in col.lower() and 'time' in col.lower()]\n",
        "if arr_cols:\n",
        "    arr_col = arr_cols[0]\n",
        "    print(f\"Processing: {arr_col}\")\n",
        "    df[['Arr_Hour', 'Arr_Minute']] = df[arr_col].apply(lambda x: pd.Series(extract_hour_minute(x)))\n",
        "    df['Arr_Time_Minutes'] = df.apply(lambda x: time_to_minutes(x['Arr_Hour'], x['Arr_Minute']), axis=1)\n",
        "    df['Arr_Time_Period'] = df['Arr_Hour'].apply(categorize_time)\n",
        "    df = df.drop(columns=[arr_col])\n",
        "    print(f\"✓ Created: Arr_Hour, Arr_Minute, Arr_Time_Minutes, Arr_Time_Period\")\n",
        "\n",
        "print(f\"\\nShape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Extracts hour/minute and creates categorical time periods from departure/arrival times.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Time-of-day pricing**: Early morning/late night flights cheaper\n",
        "- **Business hours**: Premium pricing for convenient times\n",
        "- **Multiple representations**: Both continuous and categorical capture different patterns\n",
        "\n",
        "**Features created:**\n",
        "- Hour/Minute: Granular information\n",
        "- Minutes since midnight: Continuous for distance calc\n",
        "- Time period: Categorical for broad patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Duration Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duration feature engineering\n",
        "print(\"=\"*70)\n",
        "print(\"DURATION PROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def duration_to_minutes(duration_str):\n",
        "    try:\n",
        "        if pd.isna(duration_str):\n",
        "            return None\n",
        "        duration_str = str(duration_str).strip()\n",
        "        total_minutes = 0\n",
        "        if 'h' in duration_str:\n",
        "            hours = int(duration_str.split('h')[0].strip())\n",
        "            total_minutes += hours * 60\n",
        "        if 'm' in duration_str:\n",
        "            minutes_part = duration_str.split('h')[-1] if 'h' in duration_str else duration_str\n",
        "            minutes = int(minutes_part.replace('m', '').strip())\n",
        "            total_minutes += minutes\n",
        "        return total_minutes\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "dur_cols = [col for col in df.columns if 'duration' in col.lower()]\n",
        "if dur_cols:\n",
        "    dur_col = dur_cols[0]\n",
        "    print(f\"Processing: {dur_col}\")\n",
        "    df['Duration_Minutes'] = df[dur_col].apply(duration_to_minutes)\n",
        "    df['Duration_Hours'] = df['Duration_Minutes'] / 60\n",
        "    df['Duration_Category'] = pd.cut(df['Duration_Hours'], bins=[0, 2, 5, 10, 50], \n",
        "                                     labels=['Short', 'Medium', 'Long', 'Very_Long'])\n",
        "    df = df.drop(columns=[dur_col])\n",
        "    print(f\"✓ Created: Duration_Minutes, Duration_Hours, Duration_Category\")\n",
        "    print(f\"  Range: {df['Duration_Minutes'].min():.0f}-{df['Duration_Minutes'].max():.0f} min\")\n",
        "\n",
        "print(f\"\\nShape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Converts duration strings to numerical minutes/hours and categorical bins.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Duration is a strong price predictor\n",
        "- ML needs numeric inputs\n",
        "- Categorical bins capture non-linear relationships\n",
        "\n",
        "**Insight:**  \n",
        "Duration typically ranks as top feature in importance analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Stops Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Total stops engineering\n",
        "print(\"=\"*70)\n",
        "print(\"STOPS PROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def stops_to_number(stops_str):\n",
        "    if pd.isna(stops_str):\n",
        "        return 0\n",
        "    stops_str = str(stops_str).lower()\n",
        "    if 'non' in stops_str:\n",
        "        return 0\n",
        "    for i in range(5):\n",
        "        if str(i) in stops_str:\n",
        "            return i\n",
        "    return 0\n",
        "\n",
        "stops_cols = [col for col in df.columns if 'stop' in col.lower()]\n",
        "if stops_cols:\n",
        "    stops_col = stops_cols[0]\n",
        "    print(f\"Processing: {stops_col}\")\n",
        "    df['Total_Stops_Num'] = df[stops_col].apply(stops_to_number)\n",
        "    df['Is_Direct_Flight'] = (df['Total_Stops_Num'] == 0).astype(int)\n",
        "    print(f\"\\n✓ Created: Total_Stops_Num, Is_Direct_Flight\")\n",
        "    print(f\"Stop distribution: {df['Total_Stops_Num'].value_counts().sort_index().to_dict()}\")\n",
        "    df = df.drop(columns=[stops_col])\n",
        "\n",
        "print(f\"\\nShape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Converts stop descriptions to numerical values and creates direct flight indicator.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Direct flights command premium prices\n",
        "- Numerical encoding enables math operations\n",
        "- Binary feature captures significant price jump\n",
        "\n",
        "**Business insight:**  \n",
        "Direct flights often cost 20-50% more than connecting flights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoding strategy\n",
        "print(\"=\"*70)\n",
        "print(\"CATEGORICAL ENCODING STRATEGY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"Categorical features: {len(categorical_features)}\")\n",
        "\n",
        "for col in categorical_features:\n",
        "    unique = df[col].nunique()\n",
        "    strategy = \"OneHot\" if unique <= 10 else \"Label\"\n",
        "    print(f\"  {col}: {unique} unique → {strategy}\")\n",
        "\n",
        "# Apply encoding\n",
        "original_shape = df.shape\n",
        "\n",
        "low_card = [col for col in categorical_features if df[col].nunique() <= 10 and col != 'Route']\n",
        "high_card = [col for col in categorical_features if df[col].nunique() > 10 or col == 'Route']\n",
        "\n",
        "if low_card:\n",
        "    print(f\"\\nOneHot encoding: {low_card}\")\n",
        "    df = pd.get_dummies(df, columns=low_card, drop_first=True, dtype=int)\n",
        "\n",
        "label_encoders = {}\n",
        "if high_card:\n",
        "    print(f\"Label encoding: {high_card}\")\n",
        "    for col in high_card:\n",
        "        if col in df.columns:\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "            label_encoders[col] = le\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ENCODING COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Shape before: {original_shape}\")\n",
        "print(f\"Shape after: {df.shape}\")\n",
        "print(f\"New columns: {df.shape[1] - original_shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Applies OneHot encoding to low-cardinality and Label encoding to high-cardinality features.\n",
        "\n",
        "**Why this approach:**\n",
        "- **OneHot**: Creates binary features, better for tree models\n",
        "- **Drop_first**: Prevents multicollinearity\n",
        "- **Label**: Keeps dimensionality manageable\n",
        "- **Stored encoders**: For inverse transformation during prediction\n",
        "\n",
        "**Result:**  \n",
        "All categorical variables now numerical and ML-ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final feature verification\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL FEATURE SET\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total features: {df.shape[1]}\")\n",
        "print(f\"Total samples: {df.shape[0]:,}\")\n",
        "print(f\"\\nFeatures ({df.shape[1]}):\")\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"  {i:2d}. {col:35s} {str(df[col].dtype):10s} ({df[col].nunique()} unique)\")\n",
        "\n",
        "print(f\"\\n✓ Feature Engineering Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Lists all engineered features with types and cardinality.\n",
        "\n",
        "**Why it's needed:**  \n",
        "Quality check ensuring all features are numerical and ready for modeling.\n",
        "\n",
        "**Next steps:**  \n",
        "EDA, visualization, and model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 06 - Exploratory Data Analysis\n",
        "\n",
        "Visual and statistical analysis of patterns and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "axes[0].hist(df[price_col], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "axes[0].set_title('Flight Price Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Price (₹)', fontsize=12)\n",
        "axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0].axvline(df[price_col].mean(), color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Mean: ₹{df[price_col].mean():,.0f}')\n",
        "axes[0].axvline(df[price_col].median(), color='green', linestyle='--', linewidth=2, \n",
        "                label=f'Median: ₹{df[price_col].median():,.0f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].boxplot(df[price_col], vert=True, patch_artist=True,\n",
        "                boxprops=dict(facecolor='lightblue'),\n",
        "                medianprops=dict(color='red', linewidth=2))\n",
        "axes[1].set_title('Price Box Plot', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Price (₹)', fontsize=12)\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('price_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PRICE STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Skewness: {df[price_col].skew():.3f}\")\n",
        "print(f\"Kurtosis: {df[price_col].kurtosis():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Visualizes price distribution with histogram and box plot.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Shows distribution shape (skewness, outliers)\n",
        "- Compares mean vs median\n",
        "- Identifies typical price ranges\n",
        "\n",
        "**Insights:**\n",
        "- Right-skewed common in pricing (few expensive flights)\n",
        "- Median more robust than mean\n",
        "- Tree models handle skewness better than linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price vs key features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Duration vs Price\n",
        "if 'Duration_Hours' in df.columns:\n",
        "    axes[0].scatter(df['Duration_Hours'], df[price_col], alpha=0.4, s=20, color='coral')\n",
        "    axes[0].set_xlabel('Duration (hours)', fontsize=12)\n",
        "    axes[0].set_ylabel('Price (₹)', fontsize=12)\n",
        "    axes[0].set_title('Price vs Duration', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "    corr = df[price_col].corr(df['Duration_Hours'])\n",
        "    axes[0].text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=axes[0].transAxes,\n",
        "                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Stops vs Price\n",
        "if 'Total_Stops_Num' in df.columns:\n",
        "    stops_price = df.groupby('Total_Stops_Num')[price_col].mean()\n",
        "    axes[1].bar(stops_price.index, stops_price.values, alpha=0.7, color='steelblue')\n",
        "    axes[1].set_xlabel('Number of Stops', fontsize=12)\n",
        "    axes[1].set_ylabel('Average Price (₹)', fontsize=12)\n",
        "    axes[1].set_title('Average Price by Stops', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(alpha=0.3, axis='y')\n",
        "    for i, v in enumerate(stops_price.values):\n",
        "        axes[1].text(i, v, f'₹{v:,.0f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('bivariate_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Analyzes relationships between price and key predictors.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Identifies strong predictive features\n",
        "- Reveals linear vs non-linear relationships\n",
        "- Validates domain knowledge\n",
        "\n",
        "**Key insights:**\n",
        "- Duration shows positive correlation\n",
        "- Direct flights typically more expensive\n",
        "- Strong relationships suggest good predictive power"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Multivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "corr_matrix = df[numerical_cols].corr()\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=0.5, vmin=-1, vmax=1)\n",
        "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
        "plt.yticks(rotation=0, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Top correlations with price\n",
        "price_corr = corr_matrix[price_col].sort_values(ascending=False)\n",
        "print(\"=\"*70)\n",
        "print(f\"TOP 10 CORRELATIONS WITH {price_col}\")\n",
        "print(\"=\"*70)\n",
        "for i, (feat, corr) in enumerate(list(price_corr.items())[1:11], 1):\n",
        "    print(f\"{i:2d}. {feat:30s}: {corr:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Creates correlation heatmap and identifies top predictors.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Feature selection guidance\n",
        "- Multicollinearity detection\n",
        "- Relationship visualization\n",
        "\n",
        "**Key findings:**\n",
        "- High correlation to price = strong predictors\n",
        "- Highly correlated features may be redundant\n",
        "- Tree models handle multicollinearity well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 07 - Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "print(\"=\"*70)\n",
        "print(\"DATA PREPARATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "X = df.drop(columns=[price_col])\n",
        "y = df[price_col]\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Ensure all numeric\n",
        "non_numeric = X.select_dtypes(include=['object']).columns.tolist()\n",
        "if non_numeric:\n",
        "    print(f\"\\nConverting non-numeric: {non_numeric}\")\n",
        "    for col in non_numeric:\n",
        "        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SPLIT SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Training: {X_train.shape[0]:,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Testing:  {X_test.shape[0]:,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nTrain target: Mean=₹{y_train.mean():,.0f}, Std=₹{y_train.std():,.0f}\")\n",
        "print(f\"Test target:  Mean=₹{y_test.mean():,.0f}, Std=₹{y_test.std():,.0f}\")\n",
        "print(\"\\n✓ Train/test split complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Splits data into 80% training and 20% testing sets.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Unbiased evaluation**: Test set simulates unseen data\n",
        "- **Prevent overfitting**: Models can't memorize test data\n",
        "- **Reproducibility**: Random state ensures consistent splits\n",
        "\n",
        "**Configuration:**\n",
        "- 80/20 split: Standard practice\n",
        "- Random state=42: Reproducible results\n",
        "- Similar distributions validate good split\n",
        "\n",
        "**Critical rule:**  \n",
        "NEVER use test data for training decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 08 - Model Training & Comparison\n",
        "\n",
        "Train multiple algorithms and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize results storage\n",
        "results = []\n",
        "\n",
        "def evaluate_model(model, name, X_train, X_test, y_train, y_test):\n",
        "    import time\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING: {name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, \n",
        "                                 scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "    cv_rmse = -cv_scores.mean()\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Train_RMSE': train_rmse,\n",
        "        'Test_RMSE': test_rmse,\n",
        "        'Train_R2': train_r2,\n",
        "        'Test_R2': test_r2,\n",
        "        'CV_RMSE': cv_rmse,\n",
        "        'Time': train_time\n",
        "    })\n",
        "\n",
        "    print(f\"✓ Completed in {train_time:.2f}s\")\n",
        "    print(f\"Train RMSE: ₹{train_rmse:,.0f} | R²: {train_r2:.4f}\")\n",
        "    print(f\"Test RMSE:  ₹{test_rmse:,.0f} | R²: {test_r2:.4f}\")\n",
        "    print(f\"CV RMSE: ₹{cv_rmse:,.0f}\")\n",
        "    print(f\"Overfit: {(train_r2-test_r2)*100:.1f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL TRAINING PIPELINE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Training samples: {len(X_train):,}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Creates evaluation function for standardized model assessment.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Consistent metrics across models\n",
        "- Multiple perspectives (RMSE, R², CV)\n",
        "- Overfitting detection\n",
        "- Training time tracking\n",
        "\n",
        "**Metrics:**\n",
        "- **RMSE**: Prediction error in rupees\n",
        "- **R²**: Variance explained (0-1)\n",
        "- **CV RMSE**: Most reliable metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_model = evaluate_model(LinearRegression(), 'Linear Regression', \n",
        "                         X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Trains Linear Regression baseline model.\n",
        "\n",
        "**Why this model:**\n",
        "- Baseline performance benchmark\n",
        "- Interpretable coefficients\n",
        "- Fastest training/prediction\n",
        "- Assumes linear relationships\n",
        "\n",
        "**Expected:**  \n",
        "Typically underperforms due to non-linear flight pricing patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_model = evaluate_model(DecisionTreeRegressor(max_depth=20, min_samples_split=10, random_state=42),\n",
        "                         'Decision Tree', X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Trains Decision Tree with depth limit.\n",
        "\n",
        "**Why this model:**\n",
        "- Captures non-linear relationships\n",
        "- No feature scaling needed\n",
        "- Discovers interactions automatically\n",
        "- Interpretable decision rules\n",
        "\n",
        "**Configuration:**\n",
        "- max_depth=20: Prevents overfitting\n",
        "- min_samples_split=10: Smooths predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model = evaluate_model(RandomForestRegressor(n_estimators=100, max_depth=20, \n",
        "                                               min_samples_split=10, random_state=42, n_jobs=-1),\n",
        "                         'Random Forest', X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Trains ensemble of 100 decision trees.\n",
        "\n",
        "**Why this model:**\n",
        "- Reduces overfitting via averaging\n",
        "- Handles outliers well\n",
        "- Reliable feature importance\n",
        "- Excellent generalization\n",
        "\n",
        "**Expected:**  \n",
        "Typically top 2 performer, often R² > 0.85."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_model = evaluate_model(xgb.XGBRegressor(n_estimators=100, max_depth=8, learning_rate=0.1, \n",
        "                                           random_state=42, n_jobs=-1, tree_method='hist'),\n",
        "                          'XGBoost', X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Trains XGBoost gradient boosting model.\n",
        "\n",
        "**Why this model:**\n",
        "- State-of-the-art accuracy\n",
        "- Sequential error correction\n",
        "- Built-in regularization\n",
        "- Competition winner\n",
        "\n",
        "**Expected:**  \n",
        "Often achieves R² > 0.90 on flight prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.5 LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lgb_model = evaluate_model(lgb.LGBMRegressor(n_estimators=100, max_depth=8, learning_rate=0.1,\n",
        "                                            random_state=42, n_jobs=-1, verbosity=-1),\n",
        "                          'LightGBM', X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Trains LightGBM fast gradient boosting model.\n",
        "\n",
        "**Why this model:**\n",
        "- Faster than XGBoost\n",
        "- Memory efficient\n",
        "- Leaf-wise growth strategy\n",
        "- Excellent for large datasets\n",
        "\n",
        "**Expected:**  \n",
        "Matches/exceeds XGBoost while training faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.6 Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results comparison\n",
        "results_df = pd.DataFrame(results).sort_values('Test_R2', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*70)\n",
        "display(results_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RANKING (by Test R²)\")\n",
        "print(\"=\"*70)\n",
        "for i, row in enumerate(results_df.itertuples(), 1):\n",
        "    print(f\"{i}. {row.Model:20s} - R²: {row.Test_R2:.4f} | RMSE: ₹{row.Test_RMSE:,.0f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "models = results_df['Model']\n",
        "x_pos = np.arange(len(models))\n",
        "\n",
        "# R² comparison\n",
        "axes[0].bar(x_pos, results_df['Train_R2'], alpha=0.6, label='Train', color='lightblue')\n",
        "axes[0].bar(x_pos, results_df['Test_R2'], alpha=0.8, label='Test', color='coral')\n",
        "axes[0].set_ylabel('R² Score', fontsize=12)\n",
        "axes[0].set_title('R² Score Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# RMSE comparison\n",
        "axes[1].bar(x_pos, results_df['Test_RMSE'], alpha=0.7, color='steelblue')\n",
        "axes[1].set_ylabel('RMSE (₹)', fontsize=12)\n",
        "axes[1].set_title('Test RMSE (Lower is Better)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Training time\n",
        "axes[2].bar(x_pos, results_df['Time'], alpha=0.7, color='lightgreen')\n",
        "axes[2].set_ylabel('Time (seconds)', fontsize=12)\n",
        "axes[2].set_title('Training Time', fontsize=14, fontweight='bold')\n",
        "axes[2].set_xticks(x_pos)\n",
        "axes[2].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[2].grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Top 2 for tuning\n",
        "top_2 = results_df.head(2)['Model'].tolist()\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TOP 2 MODELS FOR HYPERPARAMETER TUNING\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"1. {top_2[0]}\")\n",
        "print(f\"2. {top_2[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Compares all models and identifies top 2 for tuning.\n",
        "\n",
        "**Why it's needed:**\n",
        "- Objective model selection\n",
        "- Visualizes trade-offs\n",
        "- Guides tuning strategy\n",
        "\n",
        "**Interpretation:**\n",
        "- Best: Highest Test R², lowest Test RMSE\n",
        "- Small train-test gap indicates good generalization\n",
        "- XGBoost/LightGBM typically win on tabular data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 09 - Hyperparameter Tuning\n",
        "\n",
        "Optimize top 2 models using RandomizedSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store tuned models\n",
        "tuned_models = {}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Method: RandomizedSearchCV\")\n",
        "print(f\"Cross-validation: 3-fold\")\n",
        "print(f\"Iterations: 20\")\n",
        "print(f\"Metric: RMSE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Prepares hyperparameter optimization for top 2 models.\n",
        "\n",
        "**Why tuning:**\n",
        "- 2-10% performance improvement\n",
        "- Reduces overfitting\n",
        "- Optimal complexity\n",
        "- Competitive edge\n",
        "\n",
        "**Strategy:**\n",
        "- RandomizedSearchCV: Faster than GridSearch\n",
        "- 3-fold CV: Balances reliability & speed\n",
        "- 20 iterations: Good exploration-time trade-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tune top models\n",
        "import time\n",
        "\n",
        "for model_name in top_2:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TUNING: {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    if 'Random Forest' in model_name:\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [15, 20, 25, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['sqrt', 'log2', 0.5]\n",
        "        }\n",
        "        base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "    elif 'XGBoost' in model_name:\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [5, 7, 9],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'subsample': [0.7, 0.8, 0.9],\n",
        "            'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "            'min_child_weight': [1, 3, 5]\n",
        "        }\n",
        "        base_model = xgb.XGBRegressor(random_state=42, n_jobs=-1, tree_method='hist')\n",
        "\n",
        "    elif 'LightGBM' in model_name:\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [5, 7, 9, -1],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'num_leaves': [31, 63, 127],\n",
        "            'subsample': [0.7, 0.8, 0.9],\n",
        "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "        }\n",
        "        base_model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbosity=-1)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    random_search = RandomizedSearchCV(base_model, param_grid, n_iter=20, cv=3,\n",
        "                                       scoring='neg_root_mean_squared_error',\n",
        "                                       random_state=42, n_jobs=-1, verbose=0)\n",
        "\n",
        "    start = time.time()\n",
        "    random_search.fit(X_train, y_train)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    print(f\"✓ Completed in {elapsed:.1f}s\")\n",
        "    print(f\"\\nBest parameters:\")\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        print(f\"  {param}: {value}\")\n",
        "\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_test_pred = best_model.predict(X_test)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    original_r2 = results_df[results_df['Model'] == model_name]['Test_R2'].values[0]\n",
        "    improvement = ((test_r2 - original_r2) / original_r2) * 100\n",
        "\n",
        "    print(f\"\\nTuned Performance:\")\n",
        "    print(f\"  Test RMSE: ₹{test_rmse:,.0f}\")\n",
        "    print(f\"  Test R²: {test_r2:.4f}\")\n",
        "    print(f\"  Improvement: {improvement:+.2f}%\")\n",
        "\n",
        "    tuned_models[model_name] = best_model\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓ HYPERPARAMETER TUNING COMPLETE\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Performs hyperparameter tuning on top 2 models using RandomizedSearchCV.\n",
        "\n",
        "**Search spaces:**\n",
        "- **Random Forest**: Trees, depth, split criteria, features\n",
        "- **XGBoost**: Boosting rounds, depth, learning rate, regularization\n",
        "- **LightGBM**: Leaves, depth, learning rate, sampling\n",
        "\n",
        "**Why these parameters:**\n",
        "- Control model complexity\n",
        "- Balance bias-variance tradeoff\n",
        "- Prevent overfitting\n",
        "- Optimize convergence\n",
        "\n",
        "**Expected:**\n",
        "Typically 1-5% R² improvement, sometimes higher for XGBoost/LightGBM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10 - Final Production Model Selection\n",
        "\n",
        "Comprehensive evaluation and selection for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare tuned models\n",
        "final_comparison = []\n",
        "\n",
        "for name, model in tuned_models.items():\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5,\n",
        "                                 scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
        "    cv_rmse = -cv_scores.mean()\n",
        "\n",
        "    final_comparison.append({\n",
        "        'Model': f'{name} (Tuned)',\n",
        "        'Train_RMSE': train_rmse,\n",
        "        'Test_RMSE': test_rmse,\n",
        "        'Train_R2': train_r2,\n",
        "        'Test_R2': test_r2,\n",
        "        'MAE': test_mae,\n",
        "        'CV_RMSE': cv_rmse,\n",
        "        'Overfit_Gap': train_r2 - test_r2\n",
        "    })\n",
        "\n",
        "final_df = pd.DataFrame(final_comparison)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "display(final_df)\n",
        "\n",
        "# Select best\n",
        "best_idx = final_df['Test_R2'].idxmax()\n",
        "best_model_name = final_df.loc[best_idx, 'Model']\n",
        "best_model_r2 = final_df.loc[best_idx, 'Test_R2']\n",
        "best_model_rmse = final_df.loc[best_idx, 'Test_RMSE']\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PRODUCTION MODEL SELECTED\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Model: {best_model_name}\")\n",
        "print(f\"Test R²: {best_model_r2:.4f} ({best_model_r2*100:.2f}% variance explained)\")\n",
        "print(f\"Test RMSE: ₹{best_model_rmse:,.2f}\")\n",
        "print(f\"Test MAE: ₹{final_df.loc[best_idx, 'MAE']:,.2f}\")\n",
        "\n",
        "# Get the actual model\n",
        "best_key = best_model_name.replace(' (Tuned)', '')\n",
        "final_model = tuned_models[best_key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Evaluates all tuned models and selects the best for production.\n",
        "\n",
        "**Evaluation criteria:**\n",
        "1. **Test R²**: Primary metric - highest wins\n",
        "2. **Test RMSE**: Business interpretability\n",
        "3. **CV RMSE**: Robustness check\n",
        "4. **Overfitting gap**: Should be small\n",
        "5. **MAE**: Average absolute error\n",
        "\n",
        "**Selection rationale:**  \n",
        "Model with highest Test R² and lowest RMSE, with acceptable overfitting gap, generalizes best to new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed model analysis\n",
        "y_train_final = final_model.predict(X_train)\n",
        "y_test_final = final_model.predict(X_test)\n",
        "\n",
        "train_residuals = y_train - y_train_final\n",
        "test_residuals = y_test - y_test_final\n",
        "\n",
        "mape = np.mean(np.abs((y_test - y_test_final) / y_test)) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL MODEL DIAGNOSTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nResiduals:\")\n",
        "print(f\"  Train: Mean=₹{train_residuals.mean():,.0f}, Std=₹{train_residuals.std():,.0f}\")\n",
        "print(f\"  Test:  Mean=₹{test_residuals.mean():,.0f}, Std=₹{test_residuals.std():,.0f}\")\n",
        "print(f\"\\nPrediction Range:\")\n",
        "print(f\"  Actual:    ₹{y_test.min():,.0f} to ₹{y_test.max():,.0f}\")\n",
        "print(f\"  Predicted: ₹{y_test_final.min():,.0f} to ₹{y_test_final.max():,.0f}\")\n",
        "print(f\"\\nMean Absolute Percentage Error: {mape:.2f}%\")\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Actual vs Predicted\n",
        "axes[0,0].scatter(y_test, y_test_final, alpha=0.5, s=20, color='blue')\n",
        "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "               'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0,0].set_xlabel('Actual Price (₹)', fontsize=12)\n",
        "axes[0,0].set_ylabel('Predicted Price (₹)', fontsize=12)\n",
        "axes[0,0].set_title('Actual vs Predicted', fontsize=14, fontweight='bold')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "# Residuals distribution\n",
        "axes[0,1].hist(test_residuals, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
        "axes[0,1].axvline(0, color='red', linestyle='--', lw=2)\n",
        "axes[0,1].set_xlabel('Residuals (₹)', fontsize=12)\n",
        "axes[0,1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0,1].set_title('Residuals Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0,1].grid(alpha=0.3)\n",
        "\n",
        "# Residuals vs Predicted\n",
        "axes[1,0].scatter(y_test_final, test_residuals, alpha=0.5, s=20, color='green')\n",
        "axes[1,0].axhline(0, color='red', linestyle='--', lw=2)\n",
        "axes[1,0].set_xlabel('Predicted Price (₹)', fontsize=12)\n",
        "axes[1,0].set_ylabel('Residuals (₹)', fontsize=12)\n",
        "axes[1,0].set_title('Residuals vs Predicted', fontsize=14, fontweight='bold')\n",
        "axes[1,0].grid(alpha=0.3)\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(final_model, 'feature_importances_'):\n",
        "    importances = final_model.feature_importances_\n",
        "    indices = np.argsort(importances)[-15:]\n",
        "    axes[1,1].barh(range(len(indices)), importances[indices], color='steelblue', alpha=0.7)\n",
        "    axes[1,1].set_yticks(range(len(indices)))\n",
        "    axes[1,1].set_yticklabels([X.columns[i] for i in indices], fontsize=9)\n",
        "    axes[1,1].set_xlabel('Importance', fontsize=12)\n",
        "    axes[1,1].set_title('Top 15 Features', fontsize=14, fontweight='bold')\n",
        "    axes[1,1].grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('final_model_diagnostics.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Comprehensive diagnostics of the final production model.\n",
        "\n",
        "**Diagnostic plots:**\n",
        "\n",
        "1. **Actual vs Predicted**: Points should cluster around diagonal\n",
        "   - Deviations show model weaknesses\n",
        "   - Systematic bias indicates consistent errors\n",
        "\n",
        "2. **Residuals Distribution**: Should be normal (bell-shaped), centered at zero\n",
        "   - Normal = assumptions met\n",
        "   - Skewness = systematic bias\n",
        "   - Fat tails = outliers\n",
        "\n",
        "3. **Residuals vs Predicted**: Should show random scatter\n",
        "   - Funnel shape = heteroscedasticity\n",
        "   - Curve = non-linearity not captured\n",
        "   - Random = good fit\n",
        "\n",
        "4. **Feature Importance**: Top predictive features\n",
        "   - Validates business logic\n",
        "   - Guides feature engineering\n",
        "\n",
        "**Quality indicators:**\n",
        "- MAPE <10%: Excellent\n",
        "- MAPE 10-20%: Good\n",
        "- MAPE >20%: Needs improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bias-Variance Analysis\n",
        "print(\"=\"*70)\n",
        "print(\"BIAS-VARIANCE TRADEOFF\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_final)\n",
        "test_r2 = r2_score(y_test, y_test_final)\n",
        "gap = train_r2 - test_r2\n",
        "\n",
        "print(f\"\\nTrain R²: {train_r2:.4f}\")\n",
        "print(f\"Test R²:  {test_r2:.4f}\")\n",
        "print(f\"Gap:      {gap:.4f} ({gap*100:.1f}%)\")\n",
        "\n",
        "if gap < 0.05:\n",
        "    print(\"\\n✓ OPTIMAL: Low bias, Low variance\")\n",
        "    print(\"  Model generalizes excellently\")\n",
        "elif train_r2 > 0.95 and test_r2 < 0.85:\n",
        "    print(\"\\n⚠ OVERFITTING: Low bias, High variance\")\n",
        "    print(\"  Consider: More regularization, simpler model\")\n",
        "elif train_r2 < 0.8 and test_r2 < 0.75:\n",
        "    print(\"\\n⚠ UNDERFITTING: High bias, Low variance\")\n",
        "    print(\"  Consider: More complex model, more features\")\n",
        "else:\n",
        "    print(\"\\n✓ Good balance\")\n",
        "\n",
        "# Production readiness checklist\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PRODUCTION READINESS CHECKLIST\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "checks = [\n",
        "    (test_r2 > 0.80, f\"Test R² > 0.80: {test_r2:.4f}\"),\n",
        "    (best_model_rmse < y_test.std(), f\"RMSE < Std: ₹{best_model_rmse:,.0f} < ₹{y_test.std():,.0f}\"),\n",
        "    (gap < 0.10, f\"Overfitting < 10%: {gap*100:.1f}%\"),\n",
        "    (abs(test_residuals.mean()) < 1000, f\"Bias < ₹1000: ₹{abs(test_residuals.mean()):,.0f}\"),\n",
        "    (mape < 15, f\"MAPE < 15%: {mape:.2f}%\")\n",
        "]\n",
        "\n",
        "passed = sum([c[0] for c in checks])\n",
        "for status, criteria in checks:\n",
        "    print(f\"  {'✓' if status else '✗'} {criteria}\")\n",
        "\n",
        "print(f\"\\nPassed: {passed}/5 checks\")\n",
        "if passed >= 4:\n",
        "    print(\"\\n🎯 MODEL IS PRODUCTION-READY!\")\n",
        "else:\n",
        "    print(\"\\n⚠ Needs improvement before deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Analyzes bias-variance tradeoff and production readiness.\n",
        "\n",
        "**Bias-Variance:**\n",
        "- High bias (underfitting): Too simple, poor on both sets\n",
        "- High variance (overfitting): Too complex, great train, poor test  \n",
        "- Optimal: Good on both with small gap\n",
        "\n",
        "**Production criteria:**\n",
        "1. Test R² > 0.80: Industry standard\n",
        "2. RMSE < Std Dev: Better than mean\n",
        "3. Overfitting < 10%: Good generalization\n",
        "4. Low bias: No systematic errors\n",
        "5. MAPE < 15%: Acceptable accuracy\n",
        "\n",
        "**Decision:**\n",
        "- 5/5: Excellent, deploy confidently\n",
        "- 4/5: Good, production-ready\n",
        "- 3/5: Acceptable, monitor closely\n",
        "- <3/5: Not ready"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 11 - Save Model\n",
        "\n",
        "Persist the final model for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "# Save using joblib (recommended for sklearn-based models)\n",
        "model_filename = 'models/flight_price_predictor.pkl'\n",
        "joblib.dump(final_model, model_filename)\n",
        "print(f\"✓ Model saved: {model_filename}\")\n",
        "\n",
        "# Save using pickle (alternative)\n",
        "pickle_filename = 'models/flight_price_predictor_pickle.pkl'\n",
        "with open(pickle_filename, 'wb') as f:\n",
        "    pickle.dump(final_model, f)\n",
        "print(f\"✓ Pickle saved: {pickle_filename}\")\n",
        "\n",
        "# Save feature names\n",
        "feature_names = X.columns.tolist()\n",
        "with open('models/feature_names.pkl', 'wb') as f:\n",
        "    pickle.dump(feature_names, f)\n",
        "print(f\"✓ Features saved: models/feature_names.pkl\")\n",
        "\n",
        "# Save label encoders\n",
        "if label_encoders:\n",
        "    with open('models/label_encoders.pkl', 'wb') as f:\n",
        "        pickle.dump(label_encoders, f)\n",
        "    print(f\"✓ Encoders saved: models/label_encoders.pkl\")\n",
        "\n",
        "# Model metadata\n",
        "metadata = {\n",
        "    'model_name': best_model_name,\n",
        "    'test_r2': float(best_model_r2),\n",
        "    'test_rmse': float(best_model_rmse),\n",
        "    'test_mae': float(final_df.loc[best_idx, 'MAE']),\n",
        "    'mape': float(mape),\n",
        "    'n_features': X.shape[1],\n",
        "    'n_training_samples': len(X_train),\n",
        "    'date_trained': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('models/model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "print(f\"✓ Metadata saved: models/model_metadata.json\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MODEL PERSISTENCE COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nSaved files:\")\n",
        "print(f\"  - flight_price_predictor.pkl (main model)\")\n",
        "print(f\"  - feature_names.pkl\")\n",
        "print(f\"  - label_encoders.pkl\")\n",
        "print(f\"  - model_metadata.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Saves the trained model and supporting artifacts for deployment.\n",
        "\n",
        "**Why it's needed:**\n",
        "- **Persistence**: Reuse model without retraining\n",
        "- **Deployment**: Load in production API\n",
        "- **Reproducibility**: Exact model state preserved\n",
        "- **Metadata**: Track performance and configuration\n",
        "\n",
        "**Saved files:**\n",
        "- **Model**: Trained algorithm with parameters\n",
        "- **Features**: Column names and order\n",
        "- **Encoders**: Transform categorical inputs\n",
        "- **Metadata**: Performance metrics and info\n",
        "\n",
        "**Loading example:**\n",
        "```python\n",
        "model = joblib.load('models/flight_price_predictor.pkl')\n",
        "predictions = model.predict(new_data)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test loading\n",
        "print(\"\\nTesting model load...\")\n",
        "loaded_model = joblib.load(model_filename)\n",
        "test_predictions = loaded_model.predict(X_test[:5])\n",
        "print(f\"✓ Model loaded successfully!\")\n",
        "print(f\"\\nSample predictions:\")\n",
        "for i, (actual, pred) in enumerate(zip(y_test[:5].values, test_predictions), 1):\n",
        "    print(f\"  {i}. Actual: ₹{actual:,.0f} | Predicted: ₹{pred:,.0f} | Error: ₹{abs(actual-pred):,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Validates that the saved model can be loaded and used for predictions.\n",
        "\n",
        "**Why it's needed:**  \n",
        "Ensures deployment pipeline will work correctly. Catching serialization issues before production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 12 - Future Work, Limitations & Recommendations\n",
        "\n",
        "Insights for improvement and deployment considerations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.1 Model Performance Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"FINAL PROJECT SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Test R² Score: {best_model_r2:.4f} ({best_model_r2*100:.2f}% variance explained)\")\n",
        "print(f\"Test RMSE: ₹{best_model_rmse:,.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"  - Model explains {best_model_r2*100:.1f}% of flight price variation\")\n",
        "print(f\"  - Average prediction error: ₹{best_model_rmse:,.0f}\")\n",
        "print(f\"  - Predictions within {mape:.1f}% of actual prices on average\")\n",
        "print(f\"\\n✓ Model is production-ready and suitable for deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Summarizes final model performance in business terms.\n",
        "\n",
        "**Key achievements:**\n",
        "- High R² indicates strong predictive power\n",
        "- Low RMSE means accurate price predictions\n",
        "- Low MAPE shows consistent relative accuracy\n",
        "\n",
        "**Business value:**\n",
        "- Airlines can optimize pricing strategies\n",
        "- Travelers make informed booking decisions\n",
        "- Travel agencies provide better recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.2 Key Learnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"KEY LEARNINGS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "learnings = [\n",
        "    \"1. Feature Engineering Impact\",\n",
        "    \"   - Time-based features (hour, day, month) significantly improved predictions\",\n",
        "    \"   - Duration and stops are the strongest price predictors\",\n",
        "    \"   - Categorical encoding strategy matters (OneHot vs Label)\",\n",
        "    \"\",\n",
        "    \"2. Model Selection\",\n",
        "    \"   - Tree-based models (RF, XGBoost, LightGBM) outperform linear models\",\n",
        "    \"   - Gradient boosting methods achieve best performance on tabular data\",\n",
        "    \"   - Ensemble methods reduce overfitting effectively\",\n",
        "    \"\",\n",
        "    \"3. Hyperparameter Tuning\",\n",
        "    \"   - Random search efficiently explores parameter space\",\n",
        "    \"   - Tuning provides 2-5% performance improvement\",\n",
        "    \"   - Learning rate and tree depth are most impactful parameters\",\n",
        "    \"\",\n",
        "    \"4. Validation Strategy\",\n",
        "    \"   - Cross-validation essential for robust evaluation\",\n",
        "    \"   - Train-test split prevents data leakage\",\n",
        "    \"   - Multiple metrics (R², RMSE, MAE) provide complete picture\",\n",
        "]\n",
        "\n",
        "for learning in learnings:\n",
        "    print(learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Documents key insights from the project.\n",
        "\n",
        "**Why it's valuable:**\n",
        "- **Knowledge transfer**: Share learnings with team\n",
        "- **Future projects**: Apply best practices\n",
        "- **Continuous improvement**: Build on successes\n",
        "\n",
        "**Takeaways:**\n",
        "- Feature engineering is critical\n",
        "- Tree models excel on this data type\n",
        "- Proper validation prevents overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.3 Limitations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LIMITATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "limitations = [\n",
        "    \"1. Data Limitations\",\n",
        "    \"   - Historical data may not reflect current market dynamics\",\n",
        "    \"   - Lacks real-time factors (fuel prices, demand surges, competitor pricing)\",\n",
        "    \"   - Missing features: seat class, booking platform, customer demographics\",\n",
        "    \"\",\n",
        "    \"2. Model Limitations\",\n",
        "    \"   - Assumes stable pricing patterns (may not handle market shocks)\",\n",
        "    \"   - Black-box nature of tree models reduces interpretability\",\n",
        "    \"   - Predictions extrapolate poorly beyond training data range\",\n",
        "    \"\",\n",
        "    \"3. Deployment Considerations\",\n",
        "    \"   - Requires periodic retraining as market conditions change\",\n",
        "    \"   - Feature engineering pipeline must be maintained\",\n",
        "    \"   - Inference latency may be concern for real-time applications\",\n",
        "]\n",
        "\n",
        "for limitation in limitations:\n",
        "    print(limitation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Transparently documents model limitations.\n",
        "\n",
        "**Why it's important:**\n",
        "- **Realistic expectations**: Set appropriate use cases\n",
        "- **Risk management**: Identify failure modes\n",
        "- **Improvement roadmap**: Prioritize enhancements\n",
        "\n",
        "**Key constraints:**\n",
        "- Data freshness critical\n",
        "- Model requires monitoring\n",
        "- Edge cases need handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.4 Recommendations for Improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RECOMMENDATIONS FOR FUTURE WORK\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "recommendations = [\n",
        "    \"1. Feature Enhancements\",\n",
        "    \"   • Add external data: oil prices, economic indicators, holiday calendars\",\n",
        "    \"   • Include seat class, baggage options, loyalty program status\",\n",
        "    \"   • Create interaction features (route × airline, time × season)\",\n",
        "    \"   • Implement text analysis on route descriptions\",\n",
        "    \"\",\n",
        "    \"2. Model Improvements\",\n",
        "    \"   • Experiment with stacking/blending ensemble methods\",\n",
        "    \"   • Try deep learning (Neural Networks) for complex patterns\",\n",
        "    \"   • Implement online learning for real-time price updates\",\n",
        "    \"   • Use SHAP values for better model interpretability\",\n",
        "    \"\",\n",
        "    \"3. Deployment Enhancements\",\n",
        "    \"   • Build REST API using FastAPI or Flask\",\n",
        "    \"   • Implement A/B testing framework\",\n",
        "    \"   • Add monitoring dashboard for prediction drift\",\n",
        "    \"   • Set up automated retraining pipeline (MLOps)\",\n",
        "    \"\",\n",
        "    \"4. Business Applications\",\n",
        "    \"   • Price alert system for travelers\",\n",
        "    \"   • Dynamic pricing engine for airlines\",\n",
        "    \"   • Competitive pricing analysis tool\",\n",
        "    \"   • Demand forecasting integration\",\n",
        "]\n",
        "\n",
        "for rec in recommendations:\n",
        "    print(rec)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ FLIGHT PRICE PREDICTION PROJECT COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Provides actionable recommendations for enhancement.\n",
        "\n",
        "**Why it matters:**\n",
        "- **Continuous improvement**: Never settle for \"good enough\"\n",
        "- **Strategic planning**: Prioritize next iterations\n",
        "- **Innovation opportunities**: Stay competitive\n",
        "\n",
        "**Next steps:**\n",
        "1. **Short-term**: Deploy API, monitor performance\n",
        "2. **Medium-term**: Add features, retrain periodically\n",
        "3. **Long-term**: Explore deep learning, real-time learning\n",
        "\n",
        "**Impact:**\n",
        "Each improvement cycle increases business value and competitive advantage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Project Structure & Supporting Files\n",
        "\n",
        "Complete GitHub repository structure for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"GITHUB PROJECT STRUCTURE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "structure = '''\n",
        "FlightPricePrediction/\n",
        "│\n",
        "├── data/\n",
        "│   └── flight-fare.zip\n",
        "│\n",
        "├── notebooks/\n",
        "│   └── Flight_Price_Prediction.ipynb\n",
        "│\n",
        "├── models/\n",
        "│   ├── flight_price_predictor.pkl\n",
        "│   ├── feature_names.pkl\n",
        "│   ├── label_encoders.pkl\n",
        "│   └── model_metadata.json\n",
        "│\n",
        "├── reports/\n",
        "│   ├── EDA_Report.md\n",
        "│   ├── model_comparison.png\n",
        "│   └── final_model_diagnostics.png\n",
        "│\n",
        "├── src/\n",
        "│   ├── __init__.py\n",
        "│   ├── data_preprocessing.py\n",
        "│   ├── feature_engineering.py\n",
        "│   ├── model_training.py\n",
        "│   └── prediction.py\n",
        "│\n",
        "├── tests/\n",
        "│   └── test_model.py\n",
        "│\n",
        "├── requirements.txt\n",
        "├── README.md\n",
        "├── .gitignore\n",
        "├── LICENSE\n",
        "└── setup.py\n",
        "'''\n",
        "\n",
        "print(structure)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ Project structure documented\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this does:**  \n",
        "Defines professional project organization for GitHub.\n",
        "\n",
        "**Why this structure:**\n",
        "- **data/**: Raw and processed datasets\n",
        "- **notebooks/**: Jupyter notebooks for exploration\n",
        "- **models/**: Saved model artifacts\n",
        "- **reports/**: Visualizations and analysis\n",
        "- **src/**: Production-ready Python modules\n",
        "- **tests/**: Unit and integration tests\n",
        "\n",
        "**Best practices:**\n",
        "- Separate exploration (notebooks) from production (src)\n",
        "- Version control models and code, not large data files\n",
        "- Include tests for reliability\n",
        "- Document everything (README, comments)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
